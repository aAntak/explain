# explain

explain is an _industrial grade_ compiler for [XPLN]. It is built using `flex`, `bison` and LLVM.

[XPLN]: https://github.com/bozsahin/ceng444/blob/master/project-material/xpl-specs-fall2018.pdf

## Features

* Reasonably powerful error reporting
* Optimizations! (examples below)
* Targets X86, X86-64, PowerPC, PowerPC-64, ARM, MIPS and many more architectures

## Requirements

The project was built using the following tooling, earlier versions are not tested:

* CMake >= 3.13
* C++ compiler with C++14 core language support (gcc >= 5.1 or Clang >= 3.5)
* Boost >= 1.60
* `flex` >= 2.5
* `bison` >= 3.2
* LLVM >= 7.0.0

## Build

    mkdir build
    cd build
    cmake ..
    make

On macOS, the CMake script will issue a warning about the installed Bison version. Make sure that Bison 3.2 (or greater)
is used when building this project.

## Example usage

Write a valid XPLN program into a file, say `convert.xpln`:

    fun convert(fahr)
        return (fahr - 32) * 5 / 9;
    endf;
    
    return 0;
    
Compile with `explain`:

    $ explain convert.xpln -o convert.o

Write a driver program in C or C++:

    #include <stdio.h>
    
    extern double convert(double);
    
    int
    main(int argc, char **argv)
    {
        printf("100.0 fahr = %.2lf celcius\n", convert(100.0));
        return 0;
    }
    
Compile, link and run:

    $ clang -o main main.c convert.o
    $ ./main
    100 fahr = 37.78 celc

    
## Miscellaneous features

### LLVM IR Emitter

You can emit LLVM code by invoking `explain` with `--emit-llvm`.

    $ explain examples/fibonacci.xpln --emit-llvm -o fibonacci.ll

This emits something like the following:

    ; ModuleID = 'fibonacci.ll'
    source_filename = "explain"
    target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"
    target triple = "x86_64-apple-darwin18.0.0"
    
    define double @fib(double %n) {
    entry:
      %eq = fcmp oeq double %n, 0.000000e+00
      %eq4 = fcmp oeq double %n, 1.000000e+00
      %or = or i1 %eq, %eq4
      br i1 %or, label %then, label %else
    
    then:                                             ; preds = %entry
      ret double 1.000000e+00
    
    else:                                             ; preds = %entry
      %sub = fadd double %n, -1.000000e+00
      %call = call double @fib(double %sub)
      %sub10 = fadd double %n, -2.000000e+00
      %call11 = call double @fib(double %sub10)
      %add = fadd double %call, %call11
      ret double %add
    }
    
    define double @xpln-main() {
    entry:
      %call = call double @fib(double 1.000000e+01)
      ret double %call
    }


### AST Pretty Printer

You can obtain a pretty-printed form of the Abstract Syntax Tree (AST) by invoking `explain` with the `--pretty-ast`
flag.

    $ explain --pretty-ast -
    fun foo(a,b) return a + b; endf;
    if foo(10, 20) >= 30 return 0; else return 1; endi;
    ^D
    fun foo
      args
        arg a
        arg b
      return
        +
          a
          b
    
    fun xpln-main
      args
      if
        >=
          call foo
            args
              arg
                10
              arg
                20
          30
      then
        return
          0
      else
        return
          1

## How it works

`explain` is organized into a few simple phases.

1. Scanning and parsing the source: the `Driver` class encapsulates the scanner and the parser generated by `flex` and
`bison`. Its output is an instance of `AST::Root`.
2. AST canonicalization: a single pass on the AST is required to perform some program manipulations and verifications.
These are:
    1. Verifying that the AST is constructed successfully (no malformed nodes)
    2. Name mangling to prevent linking conflicts with C programs
    3. Organizing the top level statements into a special XPLN function
    4. Verifying that every function has at least one return statement in their body
    5. Pruning statements after a `return` statement in block statements
3. Code generation: this phase builds the LLVM IR and validates variable usages and function calls. In this phase, the
LLVM optimization passes are performed as each function is built. These optimizations are:
    1. Promoting memory references to register references
    2. Combining instructions into fewer, simpler instructions
    3. Reassociating commutative expressions for better constant propagation
    4. Eliminating common subexpressions using value numbering
    5. Control flow graph simplification by merging basic blocks, dead code elimination, etc.
4. Compiling: in this step, `explain` takes the LLVM module created in Phase III and compiles it to the target machine
architecture. An object file is created.


## Possible features?

* Even better error reporting by holding source locations in the AST